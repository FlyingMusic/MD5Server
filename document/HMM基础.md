### HMM基础

大词汇量持续语音识别技术的主要流程如下图所示。

![image-20210219171421699](C:\Users\chenyifei\AppData\Roaming\Typora\typora-user-images\image-20210219171421699.png)

从麦克输入的wave格式的语音信号首先被分割成固定长度的段，然后被转换成声学向量序列$\bold{Y}_{1:T}=\bold{y}_1,\bold{y}_1,...,\bold{y}_T$，这个过程被称为特征提取。解码器的作用是找到一个单词序列$\bold{w}_{1:L}=w_1,...,w_L$，使得能产生$\bold{Y}$的概率最大，也就是寻找
$$
\hat{\bold{w}}=arg\max_w{P(\bold{w}|\bold{Y})}
$$

但是$P(\bold{w}|\bold{Y})$不容易直接建模，所以根据贝叶斯公式，将问题转换为寻找
$$
\hat{\bold{w}}=arg\max_w\left \{ {p(\bold{w}|\bold{Y})P(\bold{w})} \right \}
$$

> 这种转换并不是上帝规定的，有些系统就是直接对$P(\bold{w}|\bold{Y})$直接建模的

公式(2)就是整个语音识别领域的理论基础，其中$p(\bold{w}|\bold{Y})$就是声学模型，而$P(\bold{w})$就是语言模型。在声学模型中，音素是声音的建模基础，比如单词"bat"，可以看做是/b/ /ae/ /t/ 三个音素组成的。英语中这样的音素大概有40多个。

> 在实际使用公式(2)时，一般会对其两边取对数，将乘法变为加法，而且要引入两个个系数：$log\,p(\bold{Y}|\bold{w})+\alpha log\,p(\bold{w})+\beta|w|$，其中$\alpha$是用来使得声学模型跟语言学模型“对标”的，参考值为8~20, $\beta$是对词长度的惩罚($|w|$就是词的长度)，参考值为0~-20。

对于给定的$w$，声学模型是通过将发音词典中对应的音素模型串联起来组成的。而这些音素模型的参数是通过训练数据（录音和对应的文字）得到的。语言模型通常是N-gram​的，也就是一个单词出现的概率只跟其前面的N-1个单词有关系。N-gram的参数需要对应语料中的N元组个数来决定。解码器在搜索过程中要引入剪枝策略来排除那些可能性相对较小的组合，否则超大计算量可能导致处理失败。当句子说完的时候，可能性最大的文本将会输出。对于现代的识别系统，也可能输出一个网格（lattices），里面含有几个可能性最大的结果。

### 特征提取

特征提取的主要目的是为音频形式的声音寻找一种替代品，这种替代品应该尽量减少音频中的信息损失以便能正确区分不同单词，另外还应该与声学模型的分布假设相匹配。例如，如果状态输出分布采用对角协方差高斯分布，那么特征向量应设计为高斯和不相关的。
一个特征向量通常对应25ms的语音数据，相邻的特征向量间有10ms的帧移。一种最常见的特征编码方式是梅尔倒谱系数（MFCCs）。MFCCs是通过分帧、FFT、梅尔滤波器组、离散余弦变换（DCT）等一系列操作得到的。梅尔滤波器组的分组是非线性频率的（并不是等频率划分的），这种频率标度称为mel标度，它是模拟人耳对频率的响应而设计的。DCT的作用是对谱估计进行平滑处理，并对特征元素进行近似去相关处理。经过DCT后，第一个元素表示这个频率单元的对数能量的平均值，这个值可能会被这一帧的对数能量值取代，或者直接被抛弃。
更进一步，考虑到心理学上对声音的感受，感知线性预测（PLP）技术被引入到系统中。PLP按照心理上的感性认识对频谱进行划分（替代了MFCC的划分），先计算线性系数，然后转成倒谱系数。实践结果显示，PLP的性能比MFCC有些许提高（并不是全面压制，MFCC并没有过时），尤其是在噪音环境当中，所以很多系统开始使用PLP编码。
为了弥补基于HMM声学模型的独立性假设引入的误差，除了频谱系数，一阶和二阶差分回归系数也被加入到特征向量中。如果原始的特征向量是X，那一阶差分系数Y定义为
式中n是滑动窗口的宽度，wi是第i个窗口的回归系数。二阶差分系数的定义于此式类似，但里面用的是一阶差分系数。总之，最终得到的特征向量yt
这个特征向量的维度一般是40左右，它们是分段的，但并非完全不相干。

基于HMM的声学模型
正如前面提到的，每一个单词的发音都被分成K个基本音素组成的序列。这个序列称为这个单词的发音。考虑都多音字/词的可能，p可以通过对所有可能的发音求和得到
p(Y |w) = ? Q p(Y |Q)P(Q|w), 
式中，求和的对象是w所有可能的发音，而Q是特定的一种发音，
p(Q|w)是通过统计得到的，而p(Y |Q)可以通过下式计算
P(Q|w) = P(q (w l ) |w l )
式中，q是w的一种可能的发音
实际上，多音字的发音种类是非常有限的，所有计算这些值并不会非常困难。
每个基音q由图2.2所示的连续密度HMM表示，其(实际表示)形式为转移概率参数{a ij}和输出观测分布{b j（）}。在运行过程（也就是搜索过程）中，HMM每一个时间步都会从当前状态转换到一个连接状态。从态si到态sj的转移概率由转移概率{aij}确定。每进入一个状态时，都会根据与所进入状态相关联的分布{bj（）}生成一个特征向量。这种形式的搜索过程基于HMM的标准条件独立性假设：
1.在一定条件下，一个状态跟前面的状态都没关系。（即aij之间相互独立）
2.在一定条件下，一个状态产生一个输出的概率跟其他输出概率分布无关。（即bi之间相互独立）